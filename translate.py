def tokenize(sentence):
    return sentence.split(' ')

def correct(sentence):
    lst = tokenize(sentence)
